{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3c36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f15950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, feature_cols, target_col, window):\n",
    "    X, y = [], []\n",
    "\n",
    "    arr = df[feature_cols].values      # convert ONCE\n",
    "    target_arr = df[target_col].values # convert ONCE\n",
    "\n",
    "    for i in range(len(df) - window):\n",
    "        X.append(arr[i:i+window])\n",
    "        y.append(target_arr[i+window])\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9fd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 23\n",
      "Features: ['Open', 'High', 'Low', 'Close', 'Volume', 'MA7', 'MA21', 'EMA20', 'EMA50', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_hist', 'BB_upper', 'BB_middle', 'BB_lower', 'CCI_14', 'CMF_20', 'Stoch_K', 'Stoch_D', 'Momentum_10', 'Daily_Return', 'Log_Return']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"E://PHD/Course materials/Sem 1/Data Mining/Assignment/workspace/stock_price_trend_prediction/stock_price_pred_data_mining/Data/05_cluster_output/cluster_output_Kmeans.csv\")\n",
    "# 1. Compute next-week (5 trading days) forward return per stock\n",
    "df['next_week_close'] = df.groupby('stock_id')['Close'].shift(-5)\n",
    "df['next_week_return'] = (df['next_week_close'] - df['Close']) / df['Close']\n",
    "# 2. Binary target: 1 = uptrend, 0 = downtrend or flat\n",
    "df[\"target\"] = (df[\"Close\"].shift(-5) > df[\"Close\"]).astype(int)\n",
    "# 3. Drop rows where we can't compute future return (last 5 days per stock)\n",
    "df = df.dropna(subset=['next_week_return'])\n",
    "# Optional: drop helper column\n",
    "df = df.drop(columns=['next_week_close'])\n",
    "drop_cols = ['Date', 'stock_id', 'cluster', 'target', 'next_week_return']\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "print(\"Features:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23b21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72548, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ec4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”µ Training LSTM for Cluster 1\n",
      "Cluster 1: Final sequence shape = (55959, 20, 23)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kirut\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5089 - loss: 0.7005 - val_accuracy: 0.5034 - val_loss: 0.6943\n",
      "Epoch 2/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5139 - loss: 0.6940 - val_accuracy: 0.5093 - val_loss: 0.6945\n",
      "Epoch 3/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5210 - loss: 0.6926 - val_accuracy: 0.5063 - val_loss: 0.6938\n",
      "Epoch 4/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5228 - loss: 0.6920 - val_accuracy: 0.5084 - val_loss: 0.6930\n",
      "Epoch 5/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5236 - loss: 0.6921 - val_accuracy: 0.5086 - val_loss: 0.6934\n",
      "Epoch 6/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5227 - loss: 0.6921 - val_accuracy: 0.5104 - val_loss: 0.6929\n",
      "Epoch 7/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5252 - loss: 0.6920 - val_accuracy: 0.5103 - val_loss: 0.6930\n",
      "Epoch 8/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.5101 - val_loss: 0.6930\n",
      "Epoch 9/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5231 - loss: 0.6920 - val_accuracy: 0.5104 - val_loss: 0.6934\n",
      "Epoch 10/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5249 - loss: 0.6918 - val_accuracy: 0.5084 - val_loss: 0.6930\n",
      "Epoch 11/30\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5254 - loss: 0.6916 - val_accuracy: 0.5095 - val_loss: 0.6934\n",
      "\u001b[1m525/525\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "ROC-AUC: 0.4993\n",
      "\n",
      "    ğŸ”¹ Cluster 1 Evaluation:\n",
      "       Accuracy:  0.5236\n",
      "       Precision: 0.5234\n",
      "       Recall:    0.9992\n",
      "       Macro-F1:  0.6869\n",
      "    \n",
      "\n",
      "ğŸ”µ Training LSTM for Cluster 0\n",
      "Cluster 0: Final sequence shape = (15389, 20, 23)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kirut\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5086 - loss: 0.7152 - val_accuracy: 0.5471 - val_loss: 0.6888\n",
      "Epoch 2/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5104 - loss: 0.7042 - val_accuracy: 0.5471 - val_loss: 0.6906\n",
      "Epoch 3/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5192 - loss: 0.6964 - val_accuracy: 0.5471 - val_loss: 0.6891\n",
      "Epoch 4/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5226 - loss: 0.6950 - val_accuracy: 0.5471 - val_loss: 0.6891\n",
      "Epoch 5/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 0.6927 - val_accuracy: 0.5471 - val_loss: 0.6890\n",
      "Epoch 6/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5271 - loss: 0.6915 - val_accuracy: 0.5471 - val_loss: 0.6883\n",
      "Epoch 7/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5352 - loss: 0.6918 - val_accuracy: 0.5471 - val_loss: 0.6883\n",
      "Epoch 8/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5341 - loss: 0.6914 - val_accuracy: 0.5471 - val_loss: 0.6881\n",
      "Epoch 9/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5404 - loss: 0.6898 - val_accuracy: 0.5471 - val_loss: 0.6880\n",
      "Epoch 10/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 0.6907 - val_accuracy: 0.5471 - val_loss: 0.6882\n",
      "Epoch 11/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5357 - loss: 0.6904 - val_accuracy: 0.5471 - val_loss: 0.6879\n",
      "Epoch 12/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5401 - loss: 0.6901 - val_accuracy: 0.5471 - val_loss: 0.6890\n",
      "Epoch 13/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5387 - loss: 0.6902 - val_accuracy: 0.5471 - val_loss: 0.6884\n",
      "Epoch 14/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5394 - loss: 0.6899 - val_accuracy: 0.5471 - val_loss: 0.6884\n",
      "Epoch 15/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5391 - loss: 0.6898 - val_accuracy: 0.5471 - val_loss: 0.6882\n",
      "Epoch 16/30\n",
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5415 - loss: 0.6899 - val_accuracy: 0.5471 - val_loss: 0.6884\n",
      "\u001b[1m145/145\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ROC-AUC: 0.5034\n",
      "\n",
      "    ğŸ”¹ Cluster 0 Evaluation:\n",
      "       Accuracy:  0.4891\n",
      "       Precision: 0.4891\n",
      "       Recall:    1.0000\n",
      "       Macro-F1:  0.6569\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "WINDOW = 20  # recommended\n",
    "cluster_lstm_models = {}\n",
    "\n",
    "for cl in df['cluster'].unique():\n",
    "\n",
    "    print(f\"\\nTraining LSTM for Cluster {cl}\")\n",
    "    cluster_df = df[df['cluster'] == cl].copy().sort_values([\"stock_id\", \"Date\"])\n",
    "    \n",
    "    X_all, y_all = [], []\n",
    "\n",
    "    # ---- SEQUENCE BUILDING PER STOCK (memory-safe)\n",
    "    for sid, temp in cluster_df.groupby(\"stock_id\"):\n",
    "        if len(temp) <= WINDOW + 2:\n",
    "            continue\n",
    "        X_temp, y_temp = create_sequences(temp, feature_cols, 'target', WINDOW)\n",
    "        X_all.append(X_temp)\n",
    "        y_all.append(y_temp)\n",
    "\n",
    "    if not X_all:\n",
    "        print(f\"No usable data for cluster {cl}\")\n",
    "        continue\n",
    "\n",
    "    # Combine results\n",
    "    X = np.vstack(X_all)\n",
    "    y = np.concatenate(y_all)\n",
    "\n",
    "    print(f\"Cluster {cl}: Final sequence shape = {X.shape}\")\n",
    "\n",
    "    # ---- Train-test split (time-based)\n",
    "    split_idx = int(0.7 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    # ---- Build LSTM Model\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=False, input_shape=(WINDOW, len(feature_cols))),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # ---- Fit model\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=128,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # ---- Store model\n",
    "    cluster_lstm_models[cl] = model\n",
    "\n",
    "    # ---- Evaluate\n",
    "    y_pred_prob = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    try:\n",
    "        rocauc = roc_auc_score(y_test, y_pred_prob)\n",
    "    except:\n",
    "        rocauc = 0.0   # when only 1 class in test set\n",
    "\n",
    "    print(f\"ROC-AUC: {rocauc:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"\"\"\n",
    "    ğŸ”¹ Cluster {cl} Evaluation:\n",
    "       Accuracy:  {acc:.4f}\n",
    "       Precision: {prec:.4f}\n",
    "       Recall:    {rec:.4f}\n",
    "       Macro-F1:  {f1:.4f}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
